# ğŸ“˜ GuÃ­a Completa de NLP Koans

## ğŸ¯ CÃ³mo Usar Este Tutorial

### FilosofÃ­a de los Koans

Los **Koans** son ejercicios de aprendizaje progresivo donde:

1. **Lees** el cÃ³digo y los comentarios
2. **Ejecutas** los tests (que fallan inicialmente)
3. **Implementas** el cÃ³digo faltante
4. **Verificas** que los tests pasen
5. **Reflexionas** sobre lo aprendido

### Orden Recomendado

Sigue este orden para mÃ¡ximo aprendizaje:

```
01. TokenizaciÃ³n           â†’ Fundamentos: dividir texto
02. Stemming/Lemmatization â†’ NormalizaciÃ³n de palabras
03. POS Tagging            â†’ Etiquetado gramatical
04. NER                    â†’ Reconocimiento de entidades
05. Text Classification    â†’ ClasificaciÃ³n con ML tradicional
06. Sentiment Analysis     â†’ AnÃ¡lisis de sentimientos
07. Word Embeddings        â†’ Representaciones vectoriales
08. Transformers           â†’ Modelos modernos (BERT, GPT)
09. Language Models        â†’ GeneraciÃ³n de texto
```

## ğŸš€ InstalaciÃ³n Paso a Paso

### 1. Clonar el Repositorio

```bash
git clone <tu-repo>
cd NLP-Koan
```

### 2. Crear Entorno Virtual

**Windows (PowerShell):**
```powershell
python -m venv venv
.\venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Descargar Modelos de NLP

**spaCy (espaÃ±ol e inglÃ©s):**
```bash
python -m spacy download es_core_news_sm
python -m spacy download en_core_web_sm
```

**NLTK:**
```python
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('averaged_perceptron_tagger'); nltk.download('wordnet'); nltk.download('omw-1.4'); nltk.download('punkt_tab')"
```

## ğŸ“– Ejemplo PrÃ¡ctico: Koan 01

### Paso 1: UbicaciÃ³n

```bash
cd koans/01_tokenization
```

### Paso 2: Ejecutar Tests

```bash
pytest test_tokenization.py -v
```

VerÃ¡s algo como:
```
FAILED test_tokenization.py::TestTokenizationBasics::test_tokenize_words_nltk_spanish
AssertionError: La lista no debe estar vacÃ­a
```

### Paso 3: Abrir el CÃ³digo

Abre `tokenization.py` y encuentra:

```python
def tokenize_words_nltk(text: str) -> List[str]:
    # TODO: Implementa la tokenizaciÃ³n de palabras con nltk.word_tokenize()
    return []
```

### Paso 4: Implementar

```python
from nltk.tokenize import word_tokenize

def tokenize_words_nltk(text: str) -> List[str]:
    return word_tokenize(text)
```

### Paso 5: Verificar

```bash
pytest test_tokenization.py::TestTokenizationBasics::test_tokenize_words_nltk_spanish -v
```

Si ves `PASSED`, Â¡lo lograste! âœ…

### Paso 6: Siguiente FunciÃ³n

Repite el proceso con la siguiente funciÃ³n marcada con `# TODO`.

## ğŸ“ Consejos para Programadores Python

### Diferencias Clave con Otras LibrerÃ­as

**1. spaCy vs NLTK**

```python
# NLTK: mÃ¡s manual, mÃ¡s control
from nltk.tokenize import word_tokenize
tokens = word_tokenize("Hola mundo")

# spaCy: mÃ¡s automÃ¡tico, mÃ¡s integrado
import spacy
nlp = spacy.load("es_core_news_sm")
doc = nlp("Hola mundo")
tokens = [token.text for token in doc]
```

**2. TF-IDF vs Embeddings**

```python
# TF-IDF: basado en frecuencia (clÃ¡sico)
from sklearn.feature_extraction.text import TfidfVectorizer
vec = TfidfVectorizer()
X = vec.fit_transform(texts)

# Embeddings: basado en contexto (moderno)
import spacy
nlp = spacy.load("es_core_news_sm")
doc = nlp("Python es genial")
vector = doc.vector  # Vector de 96 dimensiones
```

**3. ML ClÃ¡sico vs Transformers**

```python
# ClÃ¡sico: scikit-learn (rÃ¡pido, menos datos)
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB()
clf.fit(X_train, y_train)

# Moderno: Transformers (potente, mÃ¡s datos)
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
result = classifier("Me encanta Python!")
```

## ğŸ’¡ Trucos y Atajos

### Ejecutar Solo Tests que Fallan

```bash
pytest --lf  # last-failed
```

### Ejecutar con MÃ¡s Detalle

```bash
pytest -vv --tb=short
```

### Ejecutar Un Solo Test

```bash
pytest koans/01_tokenization/test_tokenization.py::TestTokenizationBasics::test_tokenize_words_nltk_spanish -v
```

### Medir Cobertura

```bash
pytest --cov=koans --cov-report=html
```

## ğŸ” Debugging

### Usar Print Debugging

```python
def tokenize_words_nltk(text: str) -> List[str]:
    from nltk.tokenize import word_tokenize
    tokens = word_tokenize(text)
    print(f"DEBUG: tokens = {tokens}")  # ğŸ‘ˆ Agrega esto
    return tokens
```

### Usar el Debugger de VS Code

1. Coloca un breakpoint (F9) en la lÃ­nea que quieres inspeccionar
2. Ejecuta con Debug (F5)
3. Inspecciona variables en el panel lateral

### Usar pytest con pdb

```bash
pytest --pdb  # Se detiene en el primer error
```

## ğŸ“Š Progreso

Para ver tu progreso:

```bash
# Ejecutar todos los tests
pytest

# Ver resumen
pytest --tb=no -q
```

## ğŸ¯ Objetivos de Aprendizaje por Koan

### Koan 01: TokenizaciÃ³n
- âœ… Entender quÃ© es la tokenizaciÃ³n
- âœ… Usar NLTK para tokenizar
- âœ… Usar spaCy para tokenizar
- âœ… Diferencias entre tokenizaciÃ³n de palabras y oraciones

### Koan 02: Stemming/Lemmatization
- âœ… Diferencias entre stemming y lemmatization
- âœ… CuÃ¡ndo usar cada tÃ©cnica
- âœ… Implementar con NLTK y spaCy

### Koan 03: POS Tagging
- âœ… Identificar categorÃ­as gramaticales
- âœ… Extraer sustantivos, verbos, adjetivos
- âœ… Usar POS tags para anÃ¡lisis

### Koan 04: NER
- âœ… Reconocer entidades nombradas
- âœ… Extraer personas, lugares, organizaciones
- âœ… Aplicaciones prÃ¡cticas de NER

### Koan 05: Text Classification
- âœ… CaracterÃ­sticas TF-IDF y BoW
- âœ… Entrenar clasificadores
- âœ… Evaluar modelos

### Koan 06: Sentiment Analysis
- âœ… AnÃ¡lisis de sentimientos con Transformers
- âœ… Modelos preentrenados
- âœ… Fine-tuning (opcional)

### Koan 07: Word Embeddings
- âœ… Representaciones vectoriales
- âœ… Similitud semÃ¡ntica
- âœ… spaCy vectors y word2vec

### Koan 08: Transformers
- âœ… BERT, GPT y otros modelos
- âœ… Hugging Face Transformers
- âœ… Pipelines predefinidos

### Koan 09: Language Models
- âœ… GeneraciÃ³n de texto
- âœ… Completado automÃ¡tico
- âœ… Modelos generativos

## ğŸ¤ Pedir Ayuda

Si te quedas atascado:

1. **Lee los comentarios** en el cÃ³digo
2. **Consulta la documentaciÃ³n** oficial de cada librerÃ­a
3. **Ejecuta los tests con -vv** para ver mÃ¡s detalles
4. **Busca ejemplos** en la documentaciÃ³n de spaCy/NLTK
5. **Abre un issue** en el repositorio

## ğŸ“ Recursos Adicionales

- **spaCy**: https://spacy.io/
- **NLTK**: https://www.nltk.org/
- **Hugging Face**: https://huggingface.co/
- **scikit-learn**: https://scikit-learn.org/

Â¡Disfruta del aprendizaje! ğŸš€
