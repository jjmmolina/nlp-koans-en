# TeorÃ­a: Part-of-Speech (POS) Tagging

## ðŸ“š Tabla de Contenidos
1. [IntroducciÃ³n al POS Tagging](#introducciÃ³n)
2. [Tagsets y Etiquetas](#tagsets)
3. [Algoritmos y Modelos](#algoritmos)
4. [Herramientas](#herramientas)
5. [Aplicaciones](#aplicaciones)

---

## ðŸŽ¯ IntroducciÃ³n al POS Tagging {#introducciÃ³n}

### Â¿QuÃ© es POS Tagging?

**POS (Part-of-Speech) Tagging** es el proceso de etiquetar cada palabra en un texto con su categorÃ­a gramatical.

```python
Texto: "The quick brown fox jumps"
POS:   DET  ADJ   ADJ   NOUN VERB

# Cada palabra recibe una etiqueta gramatical
```

### Â¿Por quÃ© es Importante?

**1. DesambiguaciÃ³n:**
```python
# "book" puede ser verbo o sustantivo
"I read a book"  â†’ book/NOUN
"I book a flight" â†’ book/VERB

# "fly" puede ser verbo o sustantivo  
"Birds fly"      â†’ fly/VERB
"Catch the fly"  â†’ fly/NOUN
```

**2. Base para AnÃ¡lisis MÃ¡s Profundo:**
```
POS Tagging â†’ Chunking â†’ Parsing â†’ NER â†’ Relaciones SemÃ¡nticas
```

**3. Mejora Lemmatization:**
```python
from nltk.stem import WordNetLemmatizer

lem = WordNetLemmatizer()

# Sin POS: asume sustantivo
lem.lemmatize("better")  # â†’ better

# Con POS: adjetivo
lem.lemmatize("better", pos='a')  # â†’ good âœ…
```

---

## ðŸ·ï¸ Tagsets y Etiquetas {#tagsets}

### Penn Treebank Tagset

El mÃ¡s usado en inglÃ©s (45 etiquetas).

**Sustantivos:**
```
NN    â†’ Noun, singular (dog, car)
NNS   â†’ Noun, plural (dogs, cars)
NNP   â†’ Proper noun, singular (John, London)
NNPS  â†’ Proper noun, plural (Americans, Beatles)
```

**Verbos:**
```
VB    â†’ Verb, base form (run, eat)
VBD   â†’ Verb, past tense (ran, ate)
VBG   â†’ Verb, gerund/present participle (running, eating)
VBN   â†’ Verb, past participle (run, eaten)
VBP   â†’ Verb, non-3rd person present (I/you/we run)
VBZ   â†’ Verb, 3rd person present (he/she runs)
```

**Adjetivos y Adverbios:**
```
JJ    â†’ Adjective (big, old, green)
JJR   â†’ Adjective, comparative (bigger, older)
JJS   â†’ Adjective, superlative (biggest, oldest)
RB    â†’ Adverb (quickly, silently)
RBR   â†’ Adverb, comparative (faster)
RBS   â†’ Adverb, superlative (fastest)
```

**Otros:**
```
DT    â†’ Determiner (the, a, this)
IN    â†’ Preposition/conjunction (in, of, on)
CC    â†’ Coordinating conjunction (and, or, but)
PRP   â†’ Personal pronoun (I, you, he)
PRP$  â†’ Possessive pronoun (my, your, his)
TO    â†’ "to"
```

### Universal Dependencies Tagset

Tagset universal mÃ¡s simple (17 etiquetas).

```
NOUN  â†’ Sustantivo
VERB  â†’ Verbo
ADJ   â†’ Adjetivo
ADV   â†’ Adverbio
PRON  â†’ Pronombre
DET   â†’ Determinante
ADP   â†’ AdposiciÃ³n (preposiciÃ³n)
NUM   â†’ NÃºmero
CONJ  â†’ ConjunciÃ³n
PRT   â†’ PartÃ­cula
.     â†’ PuntuaciÃ³n
X     â†’ Otro
```

**Ejemplo Comparativo:**
```python
import spacy
import nltk

# spaCy usa Universal Dependencies
nlp = spacy.load("en_core_web_sm")
doc = nlp("The quick brown fox jumps")

for token in doc:
    print(f"{token.text:10} {token.pos_:6} {token.tag_:6}")

# The        DET    DT    
# quick      ADJ    JJ    
# brown      ADJ    JJ    
# fox        NOUN   NN    
# jumps      VERB   VBZ   
```

---

## ðŸ¤– Algoritmos y Modelos {#algoritmos}

### 1. Rule-Based Tagging

Reglas manuales basadas en patrones.

```python
# Reglas simples
if word.endswith('ing'):
    tag = 'VBG'  # Gerundio
elif word.endswith('ed'):
    tag = 'VBD'  # Pasado
elif word in ['the', 'a', 'an']:
    tag = 'DT'   # Determinante
```

**Ventajas:** Simple, interpretable
**Desventajas:** No escala, muchas excepciones

### 2. Hidden Markov Models (HMM)

Modelo probabilÃ­stico que considera:
- **EmisiÃ³n**: P(palabra|etiqueta)
- **TransiciÃ³n**: P(etiqueta_siguiente|etiqueta_actual)

```python
from nltk.tag import hmm

# Entrenar HMM tagger
trainer = hmm.HiddenMarkovModelTrainer()
tagger = trainer.train(training_data)

# Usar
tagger.tag(['The', 'dog', 'runs'])
# [('The', 'DT'), ('dog', 'NN'), ('runs', 'VBZ')]
```

**Ventajas:** Considera contexto, probabilÃ­stico
**Desventajas:** Requiere datos etiquetados

### 3. Maximum Entropy (MaxEnt)

Modelo discriminativo que usa features.

```python
# Features usadas:
# - Palabra actual
# - Sufijo (-ing, -ed, -ly)
# - Prefijo (un-, re-)
# - Palabra anterior
# - Etiqueta anterior
# - Es mayÃºscula?
# - Es nÃºmero?
```

**Ventajas:** Flexible, muchas features
**Desventajas:** MÃ¡s lento que HMM

### 4. Conditional Random Fields (CRF)

Similar a MaxEnt pero considera toda la secuencia.

```python
# Considera:
# - Palabra i-2, i-1, i, i+1, i+2
# - Etiquetas i-2, i-1
# - CaracterÃ­sticas morfolÃ³gicas
```

**Ventajas:** Estado del arte en ML clÃ¡sico
**Desventajas:** Complejo, requiere features engineerin g

### 5. Deep Learning (RNN, LSTM, Transformers)

Modelos neuronales que aprenden representaciones.

```python
# Arquitectura tÃ­pica:
# Embeddings â†’ BiLSTM â†’ CRF â†’ Tags

# spaCy usa esto por defecto
import spacy

nlp = spacy.load("en_core_web_sm")
doc = nlp("The quick brown fox")
# Usa modelo neural entrenado
```

**Ventajas:** MÃ¡xima precisiÃ³n, aprende features automÃ¡ticamente
**Desventajas:** Requiere mucho entrenamiento, recursos

---

## ðŸ› ï¸ Herramientas {#herramientas}

### NLTK

```python
import nltk
from nltk import pos_tag, word_tokenize

text = "The quick brown fox jumps over the lazy dog"
tokens = word_tokenize(text)
tags = pos_tag(tokens)

print(tags)
# [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), 
#  ('fox', 'NN'), ('jumps', 'VBZ'), ...]
```

**Tagger por Defecto:**
- MaxEnt tagger entrenado en Penn Treebank
- ~3-5% error rate

**Otros Taggers:**
```python
# HMM Tagger
from nltk.tag import hmm

# Brill Tagger (basado en transformaciones)
from nltk.tag import brill

# Tagger personalizado
from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger
```

### spaCy

```python
import spacy

nlp = spacy.load("en_core_web_sm")
doc = nlp("The quick brown fox jumps")

for token in doc:
    print(f"{token.text:10} POS: {token.pos_:6} Tag: {token.tag_:6}")

# The        POS: DET    Tag: DT    
# quick      POS: ADJ    Tag: JJ    
# brown      POS: ADJ    Tag: JJ    
# fox        POS: NOUN   Tag: NN    
# jumps      POS: VERB   Tag: VBZ   
```

**CaracterÃ­sticas:**
- âš¡ Muy rÃ¡pido
- â­ Alta precisiÃ³n (~97%)
- ðŸ§  Modelos pre-entrenados
- ðŸŒ MultilingÃ¼e

### Stanza

```python
import stanza

stanza.download('en')
nlp = stanza.Pipeline('en', processors='tokenize,pos')

doc = nlp("Barack Obama was born in Hawaii")

for sentence in doc.sentences:
    for word in sentence.words:
        print(f"{word.text:10} {word.pos:6} {word.xpos:6}")

# Barack     PROPN  NNP   
# Obama      PROPN  NNP   
# was        AUX    VBD   
# born       VERB   VBN   
```

**CaracterÃ­sticas:**
- ðŸŽ“ Academia (Stanford)
- â­â­ MÃ¡xima precisiÃ³n
- ðŸŒ 70+ idiomas

### Comparativa

| Herramienta | Velocidad | PrecisiÃ³n | Uso |
|-------------|-----------|-----------|-----|
| **NLTK** | ðŸ¢ | â­â­â­ | EducaciÃ³n |
| **spaCy** | âš¡âš¡âš¡ | â­â­â­â­ | ProducciÃ³n |
| **Stanza** | âš¡âš¡ | â­â­â­â­â­ | Academia |

---

## ðŸ’¼ Aplicaciones {#aplicaciones}

### 1. Mejora de Lemmatization

```python
import spacy

nlp = spacy.load("en_core_web_sm")

doc = nlp("better flies flying")

for token in doc:
    print(f"{token.text:10} {token.pos_:6} â†’ {token.lemma_}")

# better     ADJ    â†’ well
# flies      VERB   â†’ fly
# flying     VERB   â†’ fly
```

### 2. ExtracciÃ³n de InformaciÃ³n

```python
# Extraer sustantivos y verbos
doc = nlp("Apple announced a new iPhone at the conference")

nouns = [token.text for token in doc if token.pos_ == "NOUN"]
verbs = [token.text for token in doc if token.pos_ == "VERB"]

print("Nouns:", nouns)     # ['iPhone', 'conference']
print("Verbs:", verbs)     # ['announced']
```

### 3. Named Entity Recognition

POS tagging es un paso previo para NER.

```python
# Nombres propios (PROPN) son candidatos para entidades
doc = nlp("Barack Obama visited Paris")

proper_nouns = [token.text for token in doc if token.pos_ == "PROPN"]
print(proper_nouns)  # ['Barack', 'Obama', 'Paris']
```

### 4. Text Simplification

```python
# Identificar y simplificar adjetivos complejos
doc = nlp("The extraordinarily beautiful landscape")

for token in doc:
    if token.pos_ == "ADJ" and len(token.text) > 8:
        print(f"Simplify: {token.text}")
# Simplify: extraordinarily
```

### 5. Question Answering

```python
# Identificar tipo de pregunta basado en POS
questions = [
    "Who is the president?",      # PRON (who) â†’ PERSON
    "Where is Paris?",            # ADV (where) â†’ LOCATION
    "When was he born?",          # ADV (when) â†’ DATE
]

for q in questions:
    doc = nlp(q)
    if doc[0].pos_ == "PRON":
        print(f"{q} â†’ Expecting PERSON")
    elif doc[0].pos_ == "ADV":
        if doc[0].text.lower() == "where":
            print(f"{q} â†’ Expecting LOCATION")
        elif doc[0].text.lower() == "when":
            print(f"{q} â†’ Expecting DATE")
```

---

## ðŸŽ“ Resumen

**Conceptos Clave:**
- POS Tagging asigna categorÃ­as gramaticales a palabras
- Tagsets: Penn Treebank (45 tags), Universal Dependencies (17 tags)
- Algoritmos: HMM, MaxEnt, CRF, Deep Learning
- Esencial para lemmatization, NER, parsing

**PrÃ³ximos Pasos:**
- **Koan 4**: NER (usa POS tagging)
- **Koan 7**: Word Embeddings (contexto gramatical)

Â¡POS tagging es fundamental para NLP avanzado! ðŸš€
