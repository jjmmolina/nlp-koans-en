> ** Translation Note**: This file is currently in Spanish. English translation coming soon!
> For now, you can use a translator or refer to the code examples which are language-agnostic.
> Want to help translate? See [CONTRIBUTING.md](../../CONTRIBUTING.md)

---

# üí° Pistas para Koan 02: Stemming y Lemmatization

## üéØ Objetivo del Koan

Aprender a **normalizar palabras** reduci√©ndolas a su forma base:
- **Stemming**: Corta sufijos (r√°pido pero tosco)
- **Lemmatization**: Usa reglas ling√º√≠sticas (preciso pero lento)

---

## üìù Funci√≥n 1: `stem_word_porter()`

### Nivel 1: Concepto
El algoritmo Porter es el stemmer m√°s usado para ingl√©s. Corta sufijos de palabras.

### Nivel 2: Implementaci√≥n
```python
from nltk.stem import PorterStemmer
stemmer = PorterStemmer()
# Usa stemmer.stem(palabra)
```

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def stem_word_porter(word: str) -> str:
    from nltk.stem import PorterStemmer
    stemmer = PorterStemmer()
    return stemmer.stem(word)
```
</details>

---

## üìù Funci√≥n 2: `stem_word_snowball()`

### Nivel 1: Concepto
Snowball es mejor que Porter y soporta **m√∫ltiples idiomas** (espa√±ol, ingl√©s, etc.)

### Nivel 2: Implementaci√≥n
```python
from nltk.stem import SnowballStemmer
stemmer = SnowballStemmer(language)  # "spanish" o "english"
```

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def stem_word_snowball(word: str, language: str = "spanish") -> str:
    from nltk.stem import SnowballStemmer
    stemmer = SnowballStemmer(language)
    return stemmer.stem(word)
```
</details>

---

## üìù Funci√≥n 3: `stem_sentence()`

### Nivel 1: Concepto
Aplica stemming a cada palabra de una oraci√≥n.

### Nivel 2: Pasos
1. Tokeniza la oraci√≥n en palabras
2. Aplica `stem_word_snowball()` a cada palabra
3. Une las palabras con espacios

### Nivel 3: Casi la soluci√≥n
```python
from nltk.tokenize import word_tokenize
tokens = word_tokenize(sentence)
stemmed = [stem_word_snowball(token, language) for token in tokens]
return " ".join(stemmed)
```

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def stem_sentence(sentence: str, language: str = "spanish") -> str:
    from nltk.tokenize import word_tokenize
    tokens = word_tokenize(sentence)
    stemmed_tokens = [stem_word_snowball(token, language) for token in tokens]
    return " ".join(stemmed_tokens)
```
</details>

---

## üìù Funci√≥n 4: `lemmatize_word_nltk()`

### Nivel 1: Concepto
Lemmatization encuentra la **forma can√≥nica** de una palabra usando un diccionario.

### Nivel 2: POS tags
El par√°metro `pos` es importante:
- `'n'` = noun (sustantivo)
- `'v'` = verb (verbo)
- `'a'` = adjective (adjetivo)
- `'r'` = adverb (adverbio)

### Nivel 3: Implementaci√≥n
```python
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
return lemmatizer.lemmatize(word, pos=pos)
```

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def lemmatize_word_nltk(word: str, pos: str = "n") -> str:
    from nltk.stem import WordNetLemmatizer
    lemmatizer = WordNetLemmatizer()
    return lemmatizer.lemmatize(word, pos=pos)
```
</details>

---

## üìù Funci√≥n 5: `lemmatize_with_spacy()`

### Nivel 1: Concepto
spaCy hace lemmatization **autom√°ticamente** cuando procesas texto.

### Nivel 2: Implementaci√≥n
```python
import spacy
model = "es_core_news_sm" if lang == "es" else "en_core_web_sm"
nlp = spacy.load(model)
doc = nlp(text)
# Cada token tiene un atributo .lemma_
```

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def lemmatize_with_spacy(text: str, lang: str = "es") -> List[str]:
    import spacy
    model_name = "es_core_news_sm" if lang == "es" else "en_core_web_sm"
    nlp = spacy.load(model_name)
    doc = nlp(text)
    return [token.lemma_ for token in doc]
```
</details>

---

## üìù Funci√≥n 6: `compare_stem_vs_lemma()`

### Nivel 1: Concepto
Compara los resultados de stemming vs lemmatization para la misma palabra.

### Nivel 2: Pasos
1. Obt√©n el stem con `stem_word_snowball()`
2. Obt√©n el lema con `lemmatize_with_spacy()`
3. Retorna diccionario con ambos

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def compare_stem_vs_lemma(word: str, language: str = "spanish") -> dict:
    stem = stem_word_snowball(word, language)
    lemmas = lemmatize_with_spacy(word, lang="es" if language == "spanish" else "en")
    lemma = lemmas[0] if lemmas else word
    
    return {
        "original": word,
        "stem": stem,
        "lemma": lemma
    }
```
</details>

---

## üìù Funci√≥n 7: `normalize_text()`

### Nivel 1: Concepto
Normaliza un texto completo usando stemming o lemmatization seg√∫n el m√©todo elegido.

### Nivel 2: Pasos
```python
if method == "stem":
    # Usa stem_sentence()
elif method == "lemma":
    # Usa lemmatize_with_spacy() y une con espacios
```

### ‚úÖ Soluci√≥n
<details>
<summary>Click para ver</summary>

```python
def normalize_text(text: str, method: str = "lemma", language: str = "spanish") -> str:
    if method == "stem":
        return stem_sentence(text, language)
    elif method == "lemma":
        lemmas = lemmatize_with_spacy(text, lang="es" if language == "spanish" else "en")
        return " ".join(lemmas)
    else:
        return text
```
</details>

---

## üéØ Conceptos Clave

### Diferencia Stem vs Lemma

| Aspecto | Stemming | Lemmatization |
|---------|----------|---------------|
| **Velocidad** | R√°pido | M√°s lento |
| **Precisi√≥n** | Aproximado | Preciso |
| **Resultado** | Puede no ser palabra real | Siempre palabra v√°lida |
| **Ejemplo** | "corriendo" ‚Üí "corr" | "corriendo" ‚Üí "correr" |

### ¬øCu√°ndo usar cada uno?

**Usa Stemming cuando**:
- Necesitas velocidad
- Precisi√≥n no es cr√≠tica
- B√∫squeda de texto / IR

**Usa Lemmatization cuando**:
- Necesitas precisi√≥n
- An√°lisis ling√º√≠stico
- Interpretaci√≥n humana

## üí° Tips

1. **Porter solo funciona bien para ingl√©s**
2. **Snowball soporta 15+ idiomas**
3. **spaCy hace lemmatization gratis** cuando procesas texto
4. **Para espa√±ol, lemmatization > stemming**

## üöÄ Siguiente Paso

Una vez completo, ve al **Koan 03: POS Tagging**!
